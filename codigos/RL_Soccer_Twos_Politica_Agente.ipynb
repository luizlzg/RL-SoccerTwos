{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff387aec-10ee-4c7a-ae16-79b30214cd55",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45be926-5eeb-4790-9918-6868f167ccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install soccer-twos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fb6ef3-fb74-45bd-8111-56ad3bdb6c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install protobuf==3.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25c1962-f8c6-4514-b0e3-532f10397ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym==0.19.0\n",
    "!pip install gym-unity==0.27.0\n",
    "!pip install mlagents==0.27.0\n",
    "!pip install mlagents-envs==0.27.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf3cb3f-e385-43f9-aea7-de81f6b765f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports e utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6362b80-0f96-4d1e-9938-f34f4f0466e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gym\n",
    "import ray\n",
    "from ray import tune\n",
    "from soccer_twos import EnvType\n",
    "import numpy as np\n",
    "import os\n",
    "from ray.rllib import MultiAgentEnv\n",
    "from ray.rllib.agents.ppo import ppo\n",
    "from ray.tune.logger import pretty_print\n",
    "import soccer_twos\n",
    "import collections\n",
    "import random\n",
    "from collections import deque\n",
    "from gym_unity.envs import ActionFlattener\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27373232-8c5d-43e9-a47f-abdb6c083925",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLLibWrapper(gym.core.Wrapper, MultiAgentEnv):\n",
    "    \"\"\"\n",
    "    A RLLib wrapper so our env can inherit from MultiAgentEnv.\n",
    "    \"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def create_rllib_env(env_config: dict = {}):\n",
    "    \"\"\"\n",
    "    Creates a RLLib environment and prepares it to be instantiated by Ray workers.\n",
    "    Args:\n",
    "        env_config: configuration for the environment.\n",
    "            You may specify the following keys:\n",
    "            - variation: one of soccer_twos.EnvType. Defaults to EnvType.multiagent_player.\n",
    "            - opponent_policy: a Callable for your agent to train against. Defaults to a random policy.\n",
    "    \"\"\"\n",
    "    if hasattr(env_config, \"worker_index\"):\n",
    "        env_config[\"worker_id\"] = (\n",
    "            env_config.worker_index * env_config.get(\"num_envs_per_worker\", 1)\n",
    "            + env_config.vector_index\n",
    "        )\n",
    "    env = soccer_twos.make(**env_config)\n",
    "    if \"multiagent\" in env_config and not env_config[\"multiagent\"]:\n",
    "        \n",
    "        return env\n",
    "    return RLLibWrapper(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e25869-0987-4d08-a5ef-22c20d21d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tune.registry.register_env(\"Soccer\", create_rllib_env)\n",
    "temp_env = create_rllib_env({\"variation\": EnvType.multiagent_player})\n",
    "obs_space = temp_env.observation_space\n",
    "act_space = temp_env.action_space\n",
    "temp_env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb3b450-7e79-43c7-b310-e39286059ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_policy(agent_id):\n",
    "    if agent_id == 0:\n",
    "        return \"policy_01\" \n",
    "    else:\n",
    "        return np.random.choice([\"policy_01\", \"policy_02\", \"policy_03\", \"policy_04\"],1,\n",
    "                                p=[.8, .2/3, .2/3, .2/3])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac56322-bbb8-4428-b33e-7fac422581a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989b93a4-8b45-495d-b3dc-d9bd737c37b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ppo.DEFAULT_CONFIG.copy()\n",
    "checkpoint = 'resultados/ppo_1'\n",
    "confing_params = {\n",
    "        \"num_gpus\": 1,\n",
    "        \"num_workers\": 3,\n",
    "        \"num_envs_per_worker\": 1,\n",
    "        \"log_level\": \"INFO\",\n",
    "        \"framework\": \"torch\",\n",
    "        \"ignore_worker_failures\": True,\n",
    "        \"train_batch_size\": 256,\n",
    "        \"lr\": 1e-3,\n",
    "        \"lambda\": .95,\n",
    "        \"gamma\": .998,\n",
    "        \"entropy_coeff\": 0.01,\n",
    "        \"kl_coeff\": 1.0,\n",
    "        \"clip_param\": 0.2,\n",
    "        \"num_sgd_iter\": 10,\n",
    "        \"observation_filter\": \"NoFilter\",  \n",
    "        \"vf_loss_coeff\": 1e-4,    \n",
    "                               \n",
    "        \"vf_clip_param\": 1000000.0,\n",
    "        \"multiagent\": {\n",
    "            \"policies\": {\n",
    "                \"policy_01\": (None, obs_space, act_space, {}),\n",
    "                \"policy_02\": (None, obs_space, act_space, {}),\n",
    "                \"policy_03\": (None, obs_space, act_space, {}),\n",
    "                \"policy_04\": (None, obs_space, act_space, {})\n",
    "            },\n",
    "            \"policy_mapping_fn\": map_policy,\n",
    "            \n",
    "        },\n",
    "        \"env\": \"Soccer\",\n",
    "        \"env_config\": {\n",
    "            \"num_envs_per_worker\": 3,\n",
    "            \"variation\": EnvType.multiagent_player,\n",
    "        },\n",
    "    }\n",
    "\n",
    "config.update(config_params)\n",
    "trainer = ppo.PPOTrainer(\n",
    "    env=\"Soccer\",\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d377cb-a5a1-4fa4-804c-fd57cba4c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "for i in range(int(1e3)): #1000 its\n",
    "    resultados.append(trainer.train())\n",
    "    print(pretty_print(trainer.train()))\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        trainer.set_weights({\"policy_04\": trainer.get_weights([\"policy_03\"])[\"policy_03\"],\n",
    "                            \"policy_03\": trainer.get_weights([\"policy_02\"])[\"policy_02\"],\n",
    "                            \"policy_02\": trainer.get_weights([\"policy_01\"])[\"policy_01\"],\n",
    "                            })\n",
    "\n",
    "    if i % 80 == 0:\n",
    "        if not os.path.exists(checkpoint):\n",
    "            os.makedirs(checkpoint)\n",
    "        trainer.save_checkpoint(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52e0da0-5f32-4f45-aed3-85dc30edec3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resultados[0])#verificando se estava gerando certinho"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
